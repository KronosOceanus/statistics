[TOC]

# 贝叶斯估计

* 估计参数满足的分布

## 先验分布

### 单参数模型

#### Gaussian（似然）~Gamma（先验） 模型

* 假设高斯分布（参数）：$N(0, \frac{1}{\tau})$
* 似然函数（n 个样本）：$L(x_1,...,x_n|\tau)=\prod_{i=1}^n\sqrt{\frac{\tau}{2\pi}}e^{-\frac{\tau x_i^2}{2}}=(\frac{\tau}{2\pi})^\frac{n}{2}e^{-\frac{\tau}{2}\sum_{i=1}^nx_i^2}$
* 先验分布（参数作为变量）：$P(\tau;\alpha,\beta)=\frac{\beta^{\alpha}}{F(\alpha)}\tau^{\alpha-1}e^{-\beta \lambda}$
* 后验分布：$P(\tau|x)=L(x_1,...,x_n|\tau)P(\tau;\alpha,\beta)=\frac{\beta^{\alpha}}{2\pi^{\frac{n}{2}}F(\alpha)}\tau^{\frac{n}{2}+\alpha-1}e^{-(\beta+\frac{1}{2}\sum_{i=1}^nx_i^2)\tau}\propto Gamma(\alpha+\frac{n}{2},\beta+\frac{1}{2}\sum_{i=1}^nx_i^2)$

#### Bernoulli~Beta 模型

* 假设似然函数：$L(x|\theta) \propto \theta^x(1-\theta)^{n-x}$
* 先验分布：$P(\theta;\alpha,\beta)\propto\theta^{\alpha-1}(1-\theta)^{\beta-1}$
* 后验分布：$P(\theta|x)\propto \theta^{\alpha+x-1}(1-\theta)^{n-x+\beta-1}\propto Beta(\alpha+x,\beta+n+y)$

### 多元参数模型

#### Multinormal~Dirichlet 模型

* 假设似然函数（d 面筛子，n 个样本/每个样本为向量）：$L(x|\theta)\propto\prod_{j=1}^n\prod_{k=1}^d\theta_j^{x_{jk}}=\prod_{i=1}^{j\times k}\theta_i^{x_{jk}}$
* 先验分布：$P(\theta;\alpha)\propto\prod_{i=1}^n\theta_i^{\alpha_i-1}$
* 后验分布：$P(\theta|x)=\prod_{i=1}^n\theta_i^{x_{jk}+\alpha_i-1}\propto Dir(x_{jk}+\alpha_i)$

### 无信息分布

* Fisher 信息量：$I(\theta) = E[(\frac{\partial}{\partial\theta}lnP(x;\theta))^2]=-E[\frac{\partial^2}{\partial\theta^2}lnP(x;\theta)]$

#### Jerffeys 先验

* 先验分布不好选择时，选：$P(\theta)=\sqrt{I(\theta)}$

##### 例：

* $x$ ~ $N(\mu,\sigma^2)$，$\mu$ 已知，$\sigma$ 位置
* $P(x|\mu)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
* $lnP(x|\mu)=-\frac{(x-\mu)^2}{2\sigma^2}+ln(\frac{1}{\sqrt{2\pi}\sigma})$
* $I(\mu)=E[(\frac{\partial}{\partial\theta}lnP(x;\mu))^2]=E[(\frac{x-\mu}{\sigma^2})^2]=\frac{E(x-\mu)^2}{\sigma^4}=\frac{1}{\sigma^2}$
* 然后根据 $P(x|\mu)$ 和 $P(\mu)$ 算出后验 $P(\mu|x)$

# 极大后验估计

* $\theta=argmax_\theta[P(\theta|x)]$ 即 $\theta=argmax_\theta[lnP(x|\theta)+lnP(\theta)]$
* 样本数小的时候，极大似然估计趋于过拟合，用 $lnP(\theta)$（参数的先验程度）修正（正则化）

## 例：

* 假设 $x=(x_1,...,x_n)$ 独立同分布于 $N(0,I)$（其中 $x_i$ 为向量），估计 $x$ 的均值 $\mu$
* 似然函数：$L(x|\mu)=\prod_{i=1}^n\frac{1}{2\pi^{\frac{d}{2}}}e^{-\frac{(x_i-\mu)^T(x_i-\mu)}{2}}$
* 先验分布（也是高斯）：$P(\mu;\beta)= \frac{1}{(2\pi\beta^2)^{\frac{d}{2}}}e^{-\frac{\mu^T\mu}{2\beta^2}}$（参数自由选择）
* 优化函数：$PL(\mu)=ln[L(x|\mu)+P(\mu;\beta)]=-\frac{nd}{2}ln(2\pi)-\frac{1}{2}\sum_{i=1}^n||x_i-\mu||^2-\frac{d}{2}ln(2\pi\beta^2)-\frac{1}{2\beta^2}ln||\mu||^2$
* 求导估计：$\frac{\partial}{\partial\mu}PL(\mu)=\sum_{i=1}^n(x_i-\mu)-\frac{\mu}{\beta^2}=0$
* 得到：$\mu=\frac{\sum_{i=1}^nx_i}{n+\beta^{-2}}$

# 贝叶斯模型选择（与 AIC 类似）

* 极大后验/贝叶斯估计中，选取先验分布的超参数的方法

## 经验贝叶斯

* 假设先验：$P(\theta;\beta)$（其中 $\beta$ 为超参数）
* 边缘分布：$P(x;\beta)=\int\prod_{i=1}^nP(x_i|\theta)P(\theta;\beta)d\theta=ML(\beta)$
* 求：$\beta_{EB} = argmax_\beta[ML(\beta)]$

### 例：Gaussian~Gaussian 模型

* 边缘分布：$ML(\beta)=\frac{1}{(2\pi)^{\frac{n}{2}}(2\pi\beta^2)^{\frac{1}{2}}}\int e^{-\frac{1}{2}\sum_{i=1}^n(x_i-\mu)^2-\frac{\mu^2}{2\beta^2}}d\mu$
* 极大后验估计：$\hat\mu=\frac{\sum_{i=1}^nx_i}{n+\beta^{-2}}$
* 将极大后验估计配方代入边缘分布：$ML(\beta)=\frac{1}{(2\pi)^{-\frac{n}{2}}(2\pi\beta^2)^{-\frac{1}{2}}}\int e^{-\frac{1}{2}\sum_{i=1}^n[(x_i-\hat\mu)-(\mu+\hat\mu)]^2-\frac{\mu^2}{2\beta^2}}d\mu$
* 继续：$=\frac{1}{(2\pi)^{-\frac{n}{2}}(2\pi\beta^2)^{-\frac{1}{2}}} e^{-\frac{1}{2}\sum_{i=1}^n(x_i-\hat\mu)^2-\frac{\hat\mu^2}{2\beta^2}}\int e^{-\frac{(\mu-\hat\mu)^2}{2(n+\beta^{-2})^{-1}}}d\mu$
* 高斯积分：$\int e^{-\frac{(\mu-\hat\mu)^2}{2(n+\beta^{-2})^{-1}}}d\mu=(\frac{2\pi}{n+\beta^{-2}})^\frac{1}{2}$
* 继续：$=\frac{1}{(2\pi)^{\frac{n}{2}}(n\beta^2+1)^{\frac{1}{2}}} e^{-\frac{1}{2}\sum_{i=1}^n(x_i-\hat\mu)^2-\frac{\hat\mu^2}{2\beta^2}}$
* 求得最优质值：$\frac{\partial}{\partial\beta}ln[ML(\beta)]=0$

# 逼近推断

## 拉普拉斯逼近

- 逼近积分 $\int f(\theta)d\theta$
- 求极大值：$\hat\theta=argmax_{\theta}[f(\theta)]$（求导）即 $\frac{\partial}{\partial\theta}lnf(\theta)|_{\theta=\hat\theta}=0$
- $ln f(\theta)$ 在 $\hat\theta$ 处泰勒展开：$ln\hat f(\theta)=lnf(\hat\theta)+(\theta-\hat\theta)^T\frac{\partial}{\partial\theta}lnf(\theta)|_{\theta=\hat\theta}+\frac{1}{2}(\theta-\hat\theta)^TH(\theta-\hat\theta)$（其中 $H=\frac{\partial^2}{\partial\theta\partial\theta^T}lnf(\theta)|_{\theta=\hat\theta}$）
- 得：$ln\hat f(\theta)=lnf(\hat\theta)+\frac{1}{2}(\theta-\hat\theta)^TH(\theta-\hat\theta)$
- 取 $e$ 为底的指数再两边积分得：$\int\hat f(\theta)d\theta=\int f(\hat\theta)e^{\frac{1}{2}(\theta-\hat\theta)^TH(\theta-\hat\theta)}d\theta$
- 其中多元高斯分布积分：$\frac{1}{(2\pi)^\frac{d}{2}det(-H)^\frac{1}{2}}\int e^{-\frac{1}{2}(\theta-\hat\theta)^T(-H)(\theta-\hat\theta)}d\theta=1$
- 得：$\int \hat f(\theta)d\theta=f(\hat\theta)\sqrt{\frac{(2\pi)^d}{det(-H)}}\approx\int f(\theta)d\theta$

### 例：混合高斯模型

- $f(\theta)=N(\theta;0,1^2)+N(\theta;0,2^2)$，（其中 $N(\theta;\mu,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(\theta-\mu)^2}{2\sigma^2}}$）
- 极值点 $\hat\theta=0$
- 求出 $f(\theta)$ 对 $\theta$ 的一/二阶导，代入极值点得：$f(0)=\frac{3}{2\sqrt{2\pi}}$，$f'(0)=0$，$f''(0)=-\frac{9}{8\sqrt{2\pi}}$
- 计算海塞矩阵：$H=\frac{\partial^2}{\partial\theta\partial\theta^T}lnf(\theta)|_{\theta=\hat\theta}=\frac{f''(0)f(0)-f'(0)^2}{f(0)^2}=-\frac{3}{4}$
- 得：$\int f(\theta)d\theta=f(0)\sqrt\frac{2\pi}{-H}=\sqrt{3}$

### 应用：贝叶斯信息准则（BIC，与经验贝叶斯类似）

- 目的：选取超参数的原则，$n$ 是样本个数，$d$ 是模型参数
- 边缘分布：$ML(\beta)=\int \prod_{i=1}^nP(x_i|\theta)P(\theta;\beta)d\theta$
- 拉普拉斯逼近：$ML(\beta)\approx \prod_{i=1}^nP(x_i|\hat\theta)P(\hat\theta;\beta)\sqrt{\frac{(2\pi)^d}{det(-H)}}$
- 其中：$\hat\theta$ 为极值点，$f(\hat\theta)$ 为 $\prod_{i=1}^nP(x_i|\hat\theta)P(\hat\theta;\beta)$
- 两边取 ln：$ln ML(\beta)\approx\sum_{i=1}^nlnP(x_i|\hat\theta)+lnP(\hat\theta;\beta)+\frac{b}{2}ln(2\pi)-\frac{1}{2}ln(det(-H))$（其中只有第 1/4 项与参数数量有关）
- 根据大数定理：$\frac{1}{n}H=\frac{\partial^2}{\partial\theta\partial\theta^T}[\frac{1}{n}\sum_{i=1}^nlnP(x_i|\hat\theta)+\frac{1}{n}lnP(\hat\theta;\beta)] \rightarrow \frac{\partial^2}{\partial\theta\partial\theta^T}E[lnP(x|\theta)]=\widetilde H$
- 得：$det(n\widetilde H)=n^ddet(\widetilde H)$
- 得：$\frac{1}{2}ln(det(-H))\rightarrow \frac{d}{2}ln(n)+\frac{1}{2}ln(det(-\widetilde H))$
- $BIC$：$ln ML(\beta)\approx \sum_{i=1}^nlnP(x_i|\hat\theta)-\frac{d}{2}ln(n)$

