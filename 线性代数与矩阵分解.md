[TOC]

# 线性代数与矩阵分解

正交矩阵：$A^TA=E$，$A^T=A^{-1}$

## 矩阵分解

### 特征值分解（方阵）

* 设 $A$ 为 $n$ 阶矩阵，数 $\lambda$ 与 $n$ 维非零列向量 $x$ 满足 $Ax= \lambda x$
* 则 $\lambda$ 是特征值，$x$ 是矩阵特征值对应的特征向量（特征向量是正交的），$(A-\lambda E)x=0$ 是特征方程
* 特征值分解：$A = X\Lambda X^{-1}$（其中 $X$ 为特征向量组成的正交矩阵，$\Lambda$ 是特征值对角矩阵）

### 奇异值分解

* 奇异值：设A为 $m,n$ 阶矩阵，$q=min(m,n)$，$A^TA$的 $q$ 个非负特征值的算术平方根叫作 $A$ 的奇异值
* 奇异值分解：$A_{m,n}= U_m\sum_{m,n} V^T_{n}$（其中 $U，V$ 由左/右奇异向量（行/列向量）组成的正交矩阵，$\sum$ 是奇异值对角矩阵，右下角为阶数）
* 也可以说：$U，V^T$ 是 $AA^T/A^TA$ 特征值分解后的特征向量（叫做 $AA^T/A^TA$ 的特征向量，$A$ 的左/右奇异向量）矩阵

### 应用

#### 图像压缩

* 特征值分解
* 按照大小挑选特征值（优先大的），并将对应的特征向量（维数不变）重新构成矩阵

#### PCA 优化

* $X_{n,p}$ 为矩阵（$n\leq p$)，寻找 $W_{p,k}$ 给 $X_{n,p}$ 降维 $X_{n,p}W_{p,k}$，即求 $max_W[tr(W^TXX^TW)]$ $s.t$  $W^TW = 1$（迹最大则矩阵特征值最大）
* 即：$max_W[tr(W^TXX^TW)-\Lambda(I-W^TW)]$
* 对 $W$ 求导得：$XX^TW=\Lambda W$
* $X$ 的前 $k$ 个最大奇异值对应的向量组成 $W$

#### 图像去噪

* 大的奇异值包含更多信息，小的可能包含的是噪声

#### 推荐系统



